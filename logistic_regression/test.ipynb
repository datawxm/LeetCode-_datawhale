{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# 创建示例数据集\n",
    "data = {\n",
    "    'feature1': [0.1, 0.4, 0.35, 0.8, 0.3, 0.5, 0.7, 0.6, 0.2, 0.9],\n",
    "    'feature2': [0.2, 0.5, 0.3, 0.9, 0.4, 0.6, 0.8, 0.7, 0.1, 1.0],\n",
    "    'label': [0, 1, 0, 1, 0, 1, 1, 1, 0, 1]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 分离特征和标签\n",
    "X = df[['feature1', 'feature2']]\n",
    "y = df['label']\n",
    "\n",
    "# 分割数据集为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "# 创建示例数据集\n",
    "data = {\n",
    "    'feature1': [0.1, 0.4, 0.35, 0.8, 0.3, 0.5, 0.7, 0.6, 0.2, 0.9],\n",
    "    'feature2': [0.2, 0.5, 0.3, 0.9, 0.4, 0.6, 0.8, 0.7, 0.1, 1.0],\n",
    "    'label': [0, 1, 0, 1, 0, 1, 1, 1, 0, 1]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df\n",
    "X = df[['feature1', 'feature2']]\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter = 100, penalty = 'l1', solver = 'liblinear')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [0, 1]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.50         2\n",
      "   macro avg       0.25      0.50      0.33         2\n",
      "weighted avg       0.25      0.50      0.33         2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化逻辑回归模型\n",
    "model = LogisticRegression()\n",
    "\n",
    "# 训练模型\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 预测测试集\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 计算准确率\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'模型准确率: {accuracy:.2f}')\n",
    "\n",
    "# 混淆矩阵\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print('混淆矩阵:')\n",
    "print(conf_matrix)\n",
    "\n",
    "# 分类报告\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print('分类报告:')\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.3390 - loss: 1.1063 - val_accuracy: 0.5417 - val_loss: 1.0120\n",
      "Epoch 2/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6781 - loss: 1.0070 - val_accuracy: 0.7083 - val_loss: 0.9344\n",
      "Epoch 3/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7213 - loss: 0.9152 - val_accuracy: 0.7500 - val_loss: 0.8650\n",
      "Epoch 4/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7759 - loss: 0.8241 - val_accuracy: 0.7500 - val_loss: 0.8061\n",
      "Epoch 5/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7807 - loss: 0.7648 - val_accuracy: 0.7500 - val_loss: 0.7550\n",
      "Epoch 6/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7963 - loss: 0.6995 - val_accuracy: 0.7500 - val_loss: 0.7110\n",
      "Epoch 7/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8237 - loss: 0.6456 - val_accuracy: 0.7917 - val_loss: 0.6712\n",
      "Epoch 8/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8278 - loss: 0.6307 - val_accuracy: 0.7917 - val_loss: 0.6374\n",
      "Epoch 9/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7308 - loss: 0.6579 - val_accuracy: 0.8333 - val_loss: 0.6088\n",
      "Epoch 10/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7795 - loss: 0.5429 - val_accuracy: 0.8333 - val_loss: 0.5830\n",
      "Epoch 11/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8246 - loss: 0.5259 - val_accuracy: 0.8333 - val_loss: 0.5582\n",
      "Epoch 12/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8174 - loss: 0.5092 - val_accuracy: 0.8333 - val_loss: 0.5374\n",
      "Epoch 13/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8013 - loss: 0.4877 - val_accuracy: 0.8333 - val_loss: 0.5180\n",
      "Epoch 14/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8339 - loss: 0.4956 - val_accuracy: 0.8333 - val_loss: 0.5004\n",
      "Epoch 15/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8106 - loss: 0.4610 - val_accuracy: 0.8333 - val_loss: 0.4848\n",
      "Epoch 16/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8183 - loss: 0.4515 - val_accuracy: 0.8333 - val_loss: 0.4719\n",
      "Epoch 17/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8436 - loss: 0.4277 - val_accuracy: 0.8750 - val_loss: 0.4590\n",
      "Epoch 18/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8153 - loss: 0.4218 - val_accuracy: 0.8750 - val_loss: 0.4466\n",
      "Epoch 19/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8613 - loss: 0.3902 - val_accuracy: 0.8750 - val_loss: 0.4353\n",
      "Epoch 20/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8592 - loss: 0.3735 - val_accuracy: 0.9167 - val_loss: 0.4252\n",
      "Epoch 21/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8525 - loss: 0.3842 - val_accuracy: 0.9167 - val_loss: 0.4163\n",
      "Epoch 22/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8272 - loss: 0.3822 - val_accuracy: 0.9167 - val_loss: 0.4078\n",
      "Epoch 23/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8324 - loss: 0.3846 - val_accuracy: 0.9167 - val_loss: 0.4014\n",
      "Epoch 24/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8682 - loss: 0.3487 - val_accuracy: 0.9167 - val_loss: 0.3936\n",
      "Epoch 25/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8632 - loss: 0.3669 - val_accuracy: 0.9167 - val_loss: 0.3846\n",
      "Epoch 26/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8536 - loss: 0.3490 - val_accuracy: 0.9167 - val_loss: 0.3775\n",
      "Epoch 27/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8552 - loss: 0.3621 - val_accuracy: 0.9167 - val_loss: 0.3725\n",
      "Epoch 28/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8472 - loss: 0.3706 - val_accuracy: 0.9167 - val_loss: 0.3665\n",
      "Epoch 29/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9262 - loss: 0.3210 - val_accuracy: 0.9167 - val_loss: 0.3606\n",
      "Epoch 30/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8765 - loss: 0.3224 - val_accuracy: 0.9167 - val_loss: 0.3554\n",
      "Epoch 31/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9051 - loss: 0.3155 - val_accuracy: 0.9167 - val_loss: 0.3495\n",
      "Epoch 32/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8824 - loss: 0.3299 - val_accuracy: 0.9167 - val_loss: 0.3445\n",
      "Epoch 33/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8606 - loss: 0.3237 - val_accuracy: 0.9167 - val_loss: 0.3395\n",
      "Epoch 34/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8661 - loss: 0.3272 - val_accuracy: 0.9167 - val_loss: 0.3343\n",
      "Epoch 35/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9080 - loss: 0.2836 - val_accuracy: 0.9167 - val_loss: 0.3275\n",
      "Epoch 36/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9185 - loss: 0.2747 - val_accuracy: 0.9167 - val_loss: 0.3231\n",
      "Epoch 37/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8811 - loss: 0.2971 - val_accuracy: 0.9167 - val_loss: 0.3177\n",
      "Epoch 38/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9351 - loss: 0.2465 - val_accuracy: 0.9167 - val_loss: 0.3133\n",
      "Epoch 39/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8786 - loss: 0.2854 - val_accuracy: 0.9167 - val_loss: 0.3072\n",
      "Epoch 40/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9153 - loss: 0.2508 - val_accuracy: 0.9167 - val_loss: 0.3028\n",
      "Epoch 41/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9284 - loss: 0.2496 - val_accuracy: 0.9167 - val_loss: 0.2989\n",
      "Epoch 42/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9187 - loss: 0.2541 - val_accuracy: 0.9167 - val_loss: 0.2954\n",
      "Epoch 43/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9353 - loss: 0.2333 - val_accuracy: 0.9167 - val_loss: 0.2925\n",
      "Epoch 44/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9161 - loss: 0.2411 - val_accuracy: 0.9167 - val_loss: 0.2883\n",
      "Epoch 45/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9461 - loss: 0.2454 - val_accuracy: 0.9167 - val_loss: 0.2847\n",
      "Epoch 46/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9354 - loss: 0.2509 - val_accuracy: 0.9167 - val_loss: 0.2803\n",
      "Epoch 47/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9235 - loss: 0.2417 - val_accuracy: 0.9167 - val_loss: 0.2759\n",
      "Epoch 48/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9613 - loss: 0.1990 - val_accuracy: 0.9167 - val_loss: 0.2711\n",
      "Epoch 49/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9235 - loss: 0.2318 - val_accuracy: 0.9167 - val_loss: 0.2658\n",
      "Epoch 50/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9116 - loss: 0.2256 - val_accuracy: 0.9583 - val_loss: 0.2641\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9667 - loss: 0.1804\n",
      "Test Loss: 0.18040087819099426\n",
      "Test Accuracy: 0.9666666388511658\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 加载数据\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# 数据预处理\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "y = tf.keras.utils.to_categorical(y, 3)\n",
    "\n",
    "# 分割数据集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 创建顺序模型\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# 添加层\n",
    "model.add(tf.keras.layers.Dense(units=64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(tf.keras.layers.Dense(units=3, activation='softmax'))\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 训练模型\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.2)\n",
    "\n",
    "# 评估模型\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss}')\n",
    "print(f'Test Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(0)\n",
    "X = 2 * np.random.rand(100, 1)\n",
    "y = 4 + 3 * X + np.random.randn(100, 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(model.coef_)\n",
    "print(model.intercept_)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept (β0): 4.206340188711436\n",
      "Coefficient (β1): 2.9902591010048907\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 生成一些示例数据\n",
    "np.random.seed(0)\n",
    "X = 2 * np.random.rand(100, 1)\n",
    "y = 4 + 3 * X + np.random.randn(100, 1)\n",
    "\n",
    "# 拆分数据集为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 创建线性回归模型\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 预测\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 输出回归系数\n",
    "print(f\"Intercept (β0): {model.intercept_[0]}\")\n",
    "print(f\"Coefficient (β1): {model.coef_[0][0]}\")\n",
    "\n",
    "# 可视化\n",
    "plt.scatter(X, y, color='blue', label='Data points')\n",
    "plt.plot(X_test, y_pred, color='red', linewidth=2, label='Regression line')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 1.09762701],\n",
       "       [1.        , 1.43037873],\n",
       "       [1.        , 1.20552675],\n",
       "       [1.        , 1.08976637],\n",
       "       [1.        , 0.8473096 ],\n",
       "       [1.        , 1.29178823],\n",
       "       [1.        , 0.87517442],\n",
       "       [1.        , 1.783546  ],\n",
       "       [1.        , 1.92732552],\n",
       "       [1.        , 0.76688304],\n",
       "       [1.        , 1.58345008],\n",
       "       [1.        , 1.05778984],\n",
       "       [1.        , 1.13608912],\n",
       "       [1.        , 1.85119328],\n",
       "       [1.        , 0.14207212],\n",
       "       [1.        , 0.1742586 ],\n",
       "       [1.        , 0.04043679],\n",
       "       [1.        , 1.66523969],\n",
       "       [1.        , 1.5563135 ],\n",
       "       [1.        , 1.7400243 ],\n",
       "       [1.        , 1.95723668],\n",
       "       [1.        , 1.59831713],\n",
       "       [1.        , 0.92295872],\n",
       "       [1.        , 1.56105835],\n",
       "       [1.        , 0.23654885],\n",
       "       [1.        , 1.27984204],\n",
       "       [1.        , 0.28670657],\n",
       "       [1.        , 1.88933783],\n",
       "       [1.        , 1.04369664],\n",
       "       [1.        , 0.82932388],\n",
       "       [1.        , 0.52911122],\n",
       "       [1.        , 1.54846738],\n",
       "       [1.        , 0.91230066],\n",
       "       [1.        , 1.1368679 ],\n",
       "       [1.        , 0.0375796 ],\n",
       "       [1.        , 1.23527099],\n",
       "       [1.        , 1.22419145],\n",
       "       [1.        , 1.23386799],\n",
       "       [1.        , 1.88749616],\n",
       "       [1.        , 1.3636406 ],\n",
       "       [1.        , 0.7190158 ],\n",
       "       [1.        , 0.87406391],\n",
       "       [1.        , 1.39526239],\n",
       "       [1.        , 0.12045094],\n",
       "       [1.        , 1.33353343],\n",
       "       [1.        , 1.34127574],\n",
       "       [1.        , 0.42076512],\n",
       "       [1.        , 0.2578526 ],\n",
       "       [1.        , 0.6308567 ],\n",
       "       [1.        , 0.72742154],\n",
       "       [1.        , 1.14039354],\n",
       "       [1.        , 0.87720303],\n",
       "       [1.        , 1.97674768],\n",
       "       [1.        , 0.20408962],\n",
       "       [1.        , 0.41775351],\n",
       "       [1.        , 0.32261904],\n",
       "       [1.        , 1.30621665],\n",
       "       [1.        , 0.50658321],\n",
       "       [1.        , 0.93262155],\n",
       "       [1.        , 0.48885118],\n",
       "       [1.        , 0.31793917],\n",
       "       [1.        , 0.22075028],\n",
       "       [1.        , 1.31265918],\n",
       "       [1.        , 0.2763659 ],\n",
       "       [1.        , 0.39316472],\n",
       "       [1.        , 0.73745034],\n",
       "       [1.        , 1.64198646],\n",
       "       [1.        , 0.19420255],\n",
       "       [1.        , 1.67588981],\n",
       "       [1.        , 0.19219682],\n",
       "       [1.        , 1.95291893],\n",
       "       [1.        , 0.9373024 ],\n",
       "       [1.        , 1.95352218],\n",
       "       [1.        , 1.20969104],\n",
       "       [1.        , 1.47852716],\n",
       "       [1.        , 0.07837558],\n",
       "       [1.        , 0.56561393],\n",
       "       [1.        , 0.24039312],\n",
       "       [1.        , 0.5922804 ],\n",
       "       [1.        , 0.23745544],\n",
       "       [1.        , 0.63596636],\n",
       "       [1.        , 0.82852599],\n",
       "       [1.        , 0.12829499],\n",
       "       [1.        , 1.38494424],\n",
       "       [1.        , 1.13320291],\n",
       "       [1.        , 0.53077898],\n",
       "       [1.        , 1.04649611],\n",
       "       [1.        , 0.18788102],\n",
       "       [1.        , 1.15189299],\n",
       "       [1.        , 1.8585924 ],\n",
       "       [1.        , 0.6371379 ],\n",
       "       [1.        , 1.33482076],\n",
       "       [1.        , 0.26359572],\n",
       "       [1.        , 1.43265441],\n",
       "       [1.        , 0.57881219],\n",
       "       [1.        , 0.36638272],\n",
       "       [1.        , 1.17302587],\n",
       "       [1.        , 0.04021509],\n",
       "       [1.        , 1.65788006],\n",
       "       [1.        , 0.00939095]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error:  0.8014554834253336\n",
      "Mean Squared Error:  0.9177532469714293\n",
      "[[2.9902591]] [4.20634019]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Mean Absolute Error: \", mean_absolute_error(y_test, y_pred))\n",
    "print(\"Mean Squared Error: \", mean_squared_error(y_test, y_pred))\n",
    "print(model.coef_, model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "权重&偏置 [[2.11469843]\n",
      " [3.07515309]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "X = np.random.randn(100, 1)\n",
    "y = X * 2 + 3 + np.random.randn(100, 1)\n",
    "\n",
    "X_b = np.c_[X, np.ones(len(X))]\n",
    "\n",
    "learning_rate = 0.1\n",
    "n_iterations = 1000\n",
    "m = 100\n",
    "\n",
    "theta = np.random.randn(2, 1)\n",
    "for _ in range(n_iterations):\n",
    "    gradients = 2 / m * X_b.T.dot(X_b.dot(theta) - y)\n",
    "    theta -= learning_rate * gradients\n",
    "print('权重&偏置',theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# 生成一些随机数据\n",
    "np.random.seed(0)\n",
    "input_seq = np.random.randn(100, 10, 20)  # (批次大小, 序列长度, 特征维度)\n",
    "target_seq = np.random.randn(100, 10, 20) # (批次大小, 序列长度, 特征维度)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, encoder_outputs, decoder_hidden):\n",
    "        # encoder_outputs: (批次大小, 序列长度, 特征维度)\n",
    "        # decoder_hidden: (批次大小, 特征维度)\n",
    "\n",
    "        # 计算得分\n",
    "        scores = tf.matmul(encoder_outputs, decoder_hidden[:, tf.newaxis, :], transpose_b=True)  # (批次大小, 序列长度, 1)\n",
    "        scores = tf.squeeze(scores, axis=-1)  # (批次大小, 序列长度)\n",
    "\n",
    "        # 归一化得分\n",
    "        attn_weights = tf.nn.softmax(scores, axis=1)  # (批次大小, 序列长度)\n",
    "\n",
    "        # 加权求和\n",
    "        context_vector = tf.reduce_sum(encoder_outputs * attn_weights[:, :, tf.newaxis], axis=1)  # (批次大小, 特征维度)\n",
    "\n",
    "        return context_vector, attn_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, hidden_dim, **kwargs):\n",
    "        super(Encoder, self).__init__(**kwargs)\n",
    "        self.rnn = tf.keras.layers.GRU(hidden_dim, return_sequences=True, return_state=True)\n",
    "\n",
    "    def call(self, x):\n",
    "        outputs, hidden = self.rnn(x)\n",
    "        return outputs, hidden\n",
    "\n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, hidden_dim, output_dim, **kwargs):\n",
    "        super(Decoder, self).__init__(**kwargs)\n",
    "        self.rnn = tf.keras.layers.GRU(hidden_dim, return_sequences=True, return_state=True)\n",
    "        self.fc = tf.keras.layers.Dense(output_dim)\n",
    "        self.attention = Attention()\n",
    "\n",
    "    def call(self, x, encoder_outputs, hidden):\n",
    "        context_vector, attn_weights = self.attention(encoder_outputs, hidden)\n",
    "        rnn_output, hidden = self.rnn(x, initial_state=hidden)\n",
    "        rnn_output = tf.squeeze(rnn_output, axis=1)\n",
    "        output = self.fc(rnn_output + context_vector)\n",
    "        return output, hidden, attn_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 4.5657962036132815\n",
      "Epoch 2/10, Loss: 0.6646526336669922\n",
      "Epoch 3/10, Loss: 0.35649642944335935\n",
      "Epoch 4/10, Loss: 0.26039724349975585\n",
      "Epoch 5/10, Loss: 0.22430328369140626\n",
      "Epoch 6/10, Loss: 0.2065715217590332\n",
      "Epoch 7/10, Loss: 0.2015067481994629\n",
      "Epoch 8/10, Loss: 0.21181699752807617\n",
      "Epoch 9/10, Loss: 0.219794864654541\n",
      "Epoch 10/10, Loss: 0.2210584831237793\n"
     ]
    }
   ],
   "source": [
    "# 超参数\n",
    "input_dim = 20\n",
    "hidden_dim = 30\n",
    "output_dim = 20\n",
    "learning_rate = 0.01\n",
    "num_epochs = 10\n",
    "\n",
    "encoder = Encoder(hidden_dim)\n",
    "decoder = Decoder(hidden_dim, output_dim)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "@tf.function\n",
    "def train_step(input_seq, target_seq, encoder, decoder, optimizer, loss_fn):\n",
    "    with tf.GradientTape() as tape:\n",
    "        encoder_outputs, encoder_hidden = encoder(input_seq)\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        loss = 0\n",
    "        for t in range(target_seq.shape[1]):\n",
    "            decoder_input = target_seq[:, t:t+1, :]\n",
    "            decoder_output, decoder_hidden, _ = decoder(decoder_input, encoder_outputs, decoder_hidden)\n",
    "            loss += loss_fn(target_seq[:, t, :], decoder_output)\n",
    "\n",
    "    gradients = tape.gradient(loss, encoder.trainable_variables + decoder.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, encoder.trainable_variables + decoder.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    for batch in range(input_seq.shape[0]):\n",
    "        loss = train_step(input_seq[batch:batch+1], target_seq[batch:batch+1], encoder, decoder, optimizer, loss_fn)\n",
    "        epoch_loss += loss\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss.numpy() / input_seq.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 100.00%\n",
      "Model coefficients: [[ 0.46248518 -0.84445753  2.21233212  0.92744332]]\n",
      "Model intercept: [-6.52447541]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 加载鸢尾花数据集\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# 只选择两个类别进行二分类\n",
    "X = X[y != 2]\n",
    "y = y[y != 2]\n",
    "\n",
    "# 分割数据集为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 初始化逻辑回归模型\n",
    "model = LogisticRegression()\n",
    "\n",
    "# 训练模型\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 预测\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 计算准确率\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# 打印模型参数\n",
    "print(\"Model coefficients:\", model.coef_)\n",
    "print(\"Model intercept:\", model.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
